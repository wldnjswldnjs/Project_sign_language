{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0cff16",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41dcfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Found 8700 images belonging to 24 classes.\n",
      "Found 2169 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "train_dir = './team_made'\n",
    "# ImageDataGenerator를 생성해요!\n",
    "datagen = ImageDataGenerator(rescale=1/255,\n",
    "                             validation_split=0.2)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,    # target directory\n",
    "    target_size=(28,28),\n",
    "    batch_size=20,\n",
    "    class_mode='sparse',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_dir,    # target directory\n",
    "    target_size=(28,28),\n",
    "    batch_size=20,\n",
    "    class_mode='sparse',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1781485",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8e628",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc554cd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "class FixedDropout(tf.keras.layers.Dropout):\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        if self.noise_shape is None:\n",
    "            return self.noise_shape\n",
    "        symbolic_shape = K.shape(inputs)\n",
    "        noise_shape = [symbolic_shape[axis] if shape is None else shape for axis, shape in enumerate(self.noise_shape)]\n",
    "        return tuple(noise_shape)\n",
    "\n",
    "new_model = tf.keras.models.load_model('./fine_tuning_model.h5',custom_objects={'FixedDropout':FixedDropout})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5819bd8",
   "metadata": {},
   "source": [
    "## 인식캠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afd81f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 91  95 127]\n",
      "case1\n",
      "3\n",
      "@1 [173  30  30] ~ [180 255 255]\n",
      "@2 [ 0 30 30] ~ [  3 255 255]\n",
      "@3 [ 3 30 30] ~ [ 13 255 255]\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# RGB 값 가지고 오기 초기값 생성\n",
    "hsv = 0\n",
    "lower_blue1 = 0\n",
    "upper_blue1 = 0\n",
    "lower_blue2 = 0\n",
    "upper_blue2 = 0\n",
    "lower_blue3 = 0\n",
    "upper_blue3 = 0 \n",
    "\n",
    "\n",
    "def empty(x): # 트랙바 생성시 필요함\n",
    "    pass\n",
    "\n",
    "def gray(input_img):\n",
    "    for y in range(input_img.shape[0]):\n",
    "        for x in range(input_img.shape[1]):\n",
    "            input_img[y,x] = int(np.mean(input_img[y,x]))\n",
    "    gray_2d_pixel = input_img[:,:,0]\n",
    "    return gray_2d_pixel\n",
    "\n",
    "# 원하는 물체를 구분하기 위함\n",
    "def make_mask_image(img_bgr):\n",
    "    img_hsv = cv.cvtColor(img_bgr, cv.COLOR_BGR2HSV)\n",
    "    low = (0, 30, 0)\n",
    "    high = (15, 255, 255)\n",
    "    img_mask = cv.inRange(img_hsv, low, high)\n",
    "    return img_mask\n",
    "\n",
    "white_color = (255, 255, 255)\n",
    "classes = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global hsv, lower_blue1, upper_blue1, lower_blue2, upper_blue2, lower_blue3, upper_blue3, threshold\n",
    "\n",
    "    # 마우스 왼쪽 버튼 누를시 위치에 있는 픽셀값을 읽어와서 HSV로 변환 (x, y 값으로 저장)\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        print(img_color[y, x])\n",
    "        color = img_color[y, x]\n",
    "\n",
    "        one_pixel = np.uint8([[color]])\n",
    "        hsv = cv.cvtColor(one_pixel, cv.COLOR_BGR2HSV)\n",
    "        hsv = hsv[0][0]\n",
    "        \n",
    "        threshold = cv.getTrackbarPos('threshold', 'img_result')\n",
    "\n",
    "        \n",
    "        # HSV 색공간에서 마우스 클릭으로 얻은 픽셀값과 유사한 픽셀값의 범위를 정함\n",
    "        if hsv[0] < 10:\n",
    "            print(\"case1\")\n",
    "            lower_blue1 = np.array([hsv[0]-10+180, threshold, threshold]) # 색상만 조절\n",
    "            upper_blue1 = np.array([180, 255, 255])\n",
    "            lower_blue2 = np.array([0, threshold, threshold])\n",
    "            upper_blue2 = np.array([hsv[0], 255, 255])\n",
    "            lower_blue3 = np.array([hsv[0], threshold, threshold])\n",
    "            upper_blue3 = np.array([hsv[0]+10, 255, 255])\n",
    "            #     print(i-10+180, 180, 0, i)\n",
    "            #     print(i, i+10)\n",
    "\n",
    "        elif hsv[0] > 170:\n",
    "            print(\"case2\")\n",
    "            lower_blue1 = np.array([hsv[0], threshold, threshold])\n",
    "            upper_blue1 = np.array([180, 255, 255])\n",
    "            lower_blue2 = np.array([0, threshold, threshold])\n",
    "            upper_blue2 = np.array([hsv[0]+10-180, 255, 255])\n",
    "            lower_blue3 = np.array([hsv[0]-10, threshold, threshold])\n",
    "            upper_blue3 = np.array([hsv[0], 255, 255])\n",
    "            #     print(i, 180, 0, i+10-180)\n",
    "            #     print(i-10, i)\n",
    "        else:\n",
    "            print(\"case3\")\n",
    "            lower_blue1 = np.array([hsv[0], threshold, threshold])\n",
    "            upper_blue1 = np.array([hsv[0]+10, 255, 255])\n",
    "            lower_blue2 = np.array([hsv[0]-10, threshold, threshold])\n",
    "            upper_blue2 = np.array([hsv[0], 255, 255])\n",
    "            lower_blue3 = np.array([hsv[0]-10, threshold, threshold])\n",
    "            upper_blue3 = np.array([hsv[0], 255, 255])\n",
    "            #     print(i, i+10)\n",
    "            #     print(i-10, i)\n",
    "\n",
    "        print(hsv[0])\n",
    "        print(\"@1\", lower_blue1, \"~\", upper_blue1)\n",
    "        print(\"@2\", lower_blue2, \"~\", upper_blue2)\n",
    "        print(\"@3\", lower_blue3, \"~\", upper_blue3)\n",
    "\n",
    "\n",
    "        \n",
    "cv.namedWindow('img_color')\n",
    "cv.setMouseCallback('img_color', mouse_callback)\n",
    "\n",
    "cv.namedWindow('img_result')\n",
    "cv.createTrackbar('threshold', 'img_result', 0, 255, empty)\n",
    "cv.setTrackbarPos('threshold', 'img_result', 30) # 초기값 30 / 트랙바\n",
    "\n",
    "\n",
    "# 마스크 흑백\n",
    "# 컬러 원본\n",
    "# 리절트 값\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, img_color = cap.read()\n",
    "    height, width = img_color.shape[:2]\n",
    "    img_color = cv.flip(img_color, 1)\n",
    "    \n",
    "    \n",
    "#     print(img_color.shape[:2])  #(480, 640)\n",
    "   \n",
    "    img_color = cv.resize(img_color, (width, height), interpolation=cv.INTER_AREA)\n",
    "    img_hsv = cv.cvtColor(img_color, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    img_mask1 = cv.inRange(img_hsv, lower_blue1, upper_blue1)\n",
    "    img_mask2 = cv.inRange(img_hsv, lower_blue2, upper_blue2)\n",
    "    img_mask3 = cv.inRange(img_hsv, lower_blue3, upper_blue3)\n",
    "    img_mask = img_mask1 | img_mask2 | img_mask3\n",
    "    \n",
    "    kernel = np.ones((11,11), np.uint8) \n",
    "    img_mask = cv.morphologyEx(img_mask, cv.MORPH_OPEN, kernel) # 점으로 보이는 노이즈를 제거\n",
    "    img_mask = cv.morphologyEx(img_mask, cv.MORPH_CLOSE, kernel) # 검은 구멍 채우기\n",
    "\n",
    "    img_result = cv.bitwise_and(img_color, img_color, mask=img_mask)\n",
    "    \n",
    "    numOfLabels, img_label, stats, centroids = cv.connectedComponentsWithStats(img_mask)\n",
    "    \n",
    "#     img_roi=img_input[150:height-150, 250:width-250,:]\n",
    "\n",
    " # 사진을 계속 연결해서 동영상처럼 보이게 함\n",
    "    for index, centroid in enumerate(centroids):\n",
    "        if stats[index][0] == 0 and stats[index][1] == 0:\n",
    "            continue\n",
    "        \n",
    "        if np.any(np.isnan(centroid)):\n",
    "            continue\n",
    "        \n",
    "        x, y, width, height, area = stats[index]\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "        \n",
    "        # 영역을 잡아줌\n",
    "        if area > 10000:\n",
    "            cv.circle(img_color, (centerX, centerY), 10, (0, 0, 255), 10)\n",
    "            cv.rectangle(img_color, (x, y), (x+width, y+height), (0,0,255))\n",
    "            img_input = img_color.copy()\n",
    "            img_roi=img_input[:,:,:]\n",
    "            img_data = cv.resize(img_roi,(150,150))\n",
    "            img_data = img_data.reshape(-1,150,150,3)\n",
    "#             img_gray = gray(img_data)\n",
    "#             img_gray = img_gray.reshape(1,784)\n",
    "            img_norm = test_datagen.flow(img_data)\n",
    "#             norm_img_data = scaler.transform(img_gray)\n",
    "            prediction = new_model.predict_generator(img_norm)\n",
    "\n",
    "            # 왼쪽 상단에 예측값을 보여줌\n",
    "            idx = np.argmax(prediction)\n",
    "            cv2.putText(img_color, classes[idx], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, white_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    cv.imshow('img_color', img_color)\n",
    "    cv.imshow('img_mask', img_mask)\n",
    "    cv.imshow('img_result', img_result)\n",
    "\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-machine_TF2] *",
   "language": "python",
   "name": "conda-env-.conda-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
